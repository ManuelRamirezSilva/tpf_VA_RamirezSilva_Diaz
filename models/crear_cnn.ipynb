{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1dae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seeds\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Config\n",
    "DATA_DIR = \"data/stanford_cars\"\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"labels_train.csv\")\n",
    "VAL_CSV = os.path.join(DATA_DIR, \"labels_val.csv\")\n",
    "NAMES_CSV = os.path.join(DATA_DIR, \"names.csv\")\n",
    "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_IMG_DIR = os.path.join(DATA_DIR, \"validation\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "IMG_SIZE = 128\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b3042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarsDataset(Dataset):\n",
    "    def __init__(self, anno_csv, img_dir, names_csv, transform=None):\n",
    "        self.anno = pd.read_csv(anno_csv, header=None)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        with open(names_csv) as f:\n",
    "            self.class_names = [line.strip() for line in f]\n",
    "        self.num_classes = len(self.class_names)\n",
    "    def __len__(self):\n",
    "        return len(self.anno)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.anno.iloc[idx]\n",
    "        img_name = row[0]\n",
    "        label = int(row[5]) - 1\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean.tolist(), std.tolist())\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean.tolist(), std.tolist())\n",
    "])\n",
    "\n",
    "# DataLoaders\n",
    "train_ds = CarsDataset(TRAIN_CSV, TRAIN_IMG_DIR, NAMES_CSV, transform=train_transform)\n",
    "val_ds = CarsDataset(VAL_CSV, VAL_IMG_DIR, NAMES_CSV, transform=val_transform)\n",
    "train_subset = torch.utils.data.Subset(train_ds, range(int(len(train_ds)*0.25)))  # Limitar a 500 im치genes\n",
    "val_subset = torch.utils.data.Subset(val_ds, range(int(len(val_ds)*0.25)))      # Limitar a 200 im치genes\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=0)\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN (nos basamos en una VGG peque침a)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2), nn.Dropout(0.4),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (IMG_SIZE // 8) * (IMG_SIZE // 8), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca04ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 5.1691 | Train Acc: 4.80%\n",
      "           | Val   Loss: 3.7211 | Val   Acc: 6.19%\n",
      "Epoch 2/20 | Train Loss: 3.7133 | Train Acc: 8.23%\n",
      "           | Val   Loss: 3.4874 | Val   Acc: 5.45%\n",
      "Epoch 3/20 | Train Loss: 3.6232 | Train Acc: 9.60%\n",
      "           | Val   Loss: 3.4625 | Val   Acc: 12.38%\n",
      "Epoch 4/20 | Train Loss: 3.5671 | Train Acc: 9.96%\n",
      "           | Val   Loss: 3.4537 | Val   Acc: 12.38%\n",
      "Epoch 5/20 | Train Loss: 3.5366 | Train Acc: 9.78%\n",
      "           | Val   Loss: 3.4238 | Val   Acc: 11.88%\n",
      "Epoch 6/20 | Train Loss: 3.5402 | Train Acc: 10.35%\n",
      "           | Val   Loss: 3.4146 | Val   Acc: 12.13%\n",
      "Epoch 7/20 | Train Loss: 3.5040 | Train Acc: 10.28%\n",
      "           | Val   Loss: 3.4253 | Val   Acc: 13.12%\n",
      "Epoch 8/20 | Train Loss: 3.5017 | Train Acc: 9.15%\n",
      "           | Val   Loss: 3.4350 | Val   Acc: 12.38%\n",
      "Epoch 9/20 | Train Loss: 3.4938 | Train Acc: 10.84%\n",
      "           | Val   Loss: 3.3687 | Val   Acc: 12.13%\n",
      "Epoch 10/20 | Train Loss: 3.4934 | Train Acc: 10.84%\n",
      "           | Val   Loss: 3.3708 | Val   Acc: 12.62%\n",
      "Epoch 11/20 | Train Loss: 3.4912 | Train Acc: 10.20%\n",
      "           | Val   Loss: 3.4245 | Val   Acc: 12.38%\n",
      "Epoch 12/20 | Train Loss: 3.4860 | Train Acc: 10.35%\n",
      "           | Val   Loss: 3.3343 | Val   Acc: 13.12%\n",
      "Epoch 13/20 | Train Loss: 3.4656 | Train Acc: 10.98%\n",
      "           | Val   Loss: 3.3618 | Val   Acc: 12.87%\n",
      "Epoch 14/20 | Train Loss: 3.4669 | Train Acc: 10.81%\n",
      "           | Val   Loss: 3.3562 | Val   Acc: 11.88%\n",
      "Epoch 15/20 | Train Loss: 3.4744 | Train Acc: 10.84%\n",
      "           | Val   Loss: 3.3803 | Val   Acc: 12.38%\n",
      "Epoch 16/20 | Train Loss: 3.4797 | Train Acc: 10.77%\n",
      "           | Val   Loss: 3.3757 | Val   Acc: 12.87%\n",
      "Epoch 17/20 | Train Loss: 3.4590 | Train Acc: 10.91%\n",
      "           | Val   Loss: 3.3916 | Val   Acc: 12.87%\n",
      "Epoch 18/20 | Train Loss: 3.4483 | Train Acc: 10.45%\n",
      "           | Val   Loss: 3.3510 | Val   Acc: 12.38%\n",
      "Epoch 19/20 | Train Loss: 3.4455 | Train Acc: 11.12%\n",
      "           | Val   Loss: 3.3655 | Val   Acc: 12.38%\n",
      "Epoch 20/20 | Train Loss: 3.4349 | Train Acc: 10.81%\n",
      "           | Val   Loss: 3.3473 | Val   Acc: 12.13%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(num_classes=len(class_names)).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # Validaci칩n\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    # Guardar historial\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {running_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"           | Val   Loss: {val_loss/len(val_loader):.4f} | Val   Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# Guardar modelo\n",
    "torch.save(model.state_dict(), \"pesos/simplecnn_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d61414",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, EPOCHS + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Acc')\n",
    "plt.plot(epochs, val_accuracies, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
