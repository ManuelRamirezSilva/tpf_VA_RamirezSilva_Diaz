{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/jutrera/stanford-car-dataset-by-classes-folder\n",
      "¡Dataset descargado y descomprimido!\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Descargar el dataset\n",
    "dataset = 'jutrera/stanford-car-dataset-by-classes-folder'\n",
    "download_path = 'data/stanford_cars'\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "print(\"Descargando dataset...\")\n",
    "api.dataset_download_files(dataset, path=download_path, unzip=False)\n",
    "\n",
    "# Descomprimir\n",
    "zip_path = os.path.join(download_path, 'stanford-car-dataset-by-classes-folder.zip')\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(download_path)\n",
    "\n",
    "print(\"¡Dataset descargado y descomprimido!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test images have been renamed and moved to the train set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Configuration\n",
    "base_dir = 'data/stanford_cars/car_data/car_data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "offset = 8144  # Rename offset\n",
    "\n",
    "# Iterate through all subfolders in the test directory\n",
    "for subfolder in os.listdir(test_dir):\n",
    "    test_subfolder_path = os.path.join(test_dir, subfolder)\n",
    "    train_subfolder_path = os.path.join(train_dir, subfolder)\n",
    "\n",
    "    # Ensure the corresponding train subfolder exists\n",
    "    os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "\n",
    "    # Process all image files in the current test subfolder\n",
    "    for filename in os.listdir(test_subfolder_path):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Extract index, convert to int, apply offset\n",
    "            index_str = os.path.splitext(filename)[0]\n",
    "            new_index = int(index_str) + offset\n",
    "            new_filename = f\"{new_index:05d}.jpg\"\n",
    "\n",
    "            # Define full paths\n",
    "            src_path = os.path.join(test_subfolder_path, filename)\n",
    "            dst_path = os.path.join(train_subfolder_path, new_filename)\n",
    "\n",
    "            # Move and rename file\n",
    "            shutil.move(src_path, dst_path)\n",
    "\n",
    "# Optional: remove the now-empty test folder\n",
    "# shutil.rmtree(test_dir)\n",
    "\n",
    "print(\"All test images have been renamed and moved to the train set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test annotations have been modified and merged into anno_train.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Configuration\n",
    "offset = 8144\n",
    "anno_train_path = 'data/stanford_cars/anno_train.csv'\n",
    "anno_test_path = 'data/stanford_cars/anno_test.csv'\n",
    "\n",
    "# Read existing anno_train.csv\n",
    "with open(anno_train_path, 'r', newline='') as f:\n",
    "    train_rows = list(csv.reader(f))\n",
    "\n",
    "# Read, modify, and collect rows from anno_test.csv\n",
    "modified_test_rows = []\n",
    "with open(anno_test_path, 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        filename = row[0]\n",
    "        index = int(os.path.splitext(filename)[0])\n",
    "        new_filename = f\"{index + offset:05d}.jpg\"\n",
    "        new_row = [new_filename] + row[1:]\n",
    "        modified_test_rows.append(new_row)\n",
    "\n",
    "# Append modified test rows to train rows\n",
    "all_rows = train_rows + modified_test_rows\n",
    "\n",
    "# Write the updated annotations back to anno_train.csv\n",
    "with open(anno_train_path, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(\"Test annotations have been modified and merged into anno_train.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All train images have been moved to 'all_data' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "all_data_dir = os.path.join(base_dir, 'all_data')\n",
    "\n",
    "# Create the all_data directory if it doesn't exist\n",
    "os.makedirs(all_data_dir, exist_ok=True)\n",
    "\n",
    "# Walk through all subfolders in train\n",
    "for subfolder in os.listdir(train_dir):\n",
    "    subfolder_path = os.path.join(train_dir, subfolder)\n",
    "    \n",
    "    # Only proceed if it's a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith('.jpg'):\n",
    "                src = os.path.join(subfolder_path, filename)\n",
    "                dst = os.path.join(all_data_dir, filename)\n",
    "\n",
    "                # Check for filename conflict (should not happen if previous renaming was correct)\n",
    "                if os.path.exists(dst):\n",
    "                    print(f\"Warning: file {filename} already exists in all_data. Skipping.\")\n",
    "                else:\n",
    "                    shutil.move(src, dst)\n",
    "\n",
    "print(\"All train images have been moved to 'all_data' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset split into train, validation, and test with corresponding annotations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Configuration\n",
    "base_dir = 'data/stanford_cars'\n",
    "all_data_dir = os.path.join(base_dir, 'all_data')\n",
    "anno_all_path = os.path.join(base_dir, 'anno_all.csv')\n",
    "\n",
    "# Destination folders\n",
    "splits = {\n",
    "    'train': 0.7,\n",
    "    'validation': 0.1,\n",
    "    'test': 0.2,\n",
    "}\n",
    "split_dirs = {k: os.path.join(base_dir, k) for k in splits}\n",
    "\n",
    "# Create folders if not exist\n",
    "for split_dir in split_dirs.values():\n",
    "    os.makedirs(split_dir, exist_ok=True)\n",
    "\n",
    "# Read annotations into a dictionary\n",
    "annotations = {}\n",
    "with open(anno_all_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        filename = row[0]\n",
    "        annotations[filename] = row\n",
    "\n",
    "# Get and shuffle image list\n",
    "all_images = list(annotations.keys())\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Calculate split sizes\n",
    "n = len(all_images)\n",
    "n_train = int(splits['train'] * n)\n",
    "n_val = int(splits['validation'] * n)\n",
    "# The rest goes to test\n",
    "n_test = n - n_train - n_val\n",
    "\n",
    "# Partition images\n",
    "train_images = all_images[:n_train]\n",
    "val_images = all_images[n_train:n_train + n_val]\n",
    "test_images = all_images[n_train + n_val:]\n",
    "\n",
    "split_map = {\n",
    "    'train': train_images,\n",
    "    'validation': val_images,\n",
    "    'test': test_images,\n",
    "}\n",
    "\n",
    "# Move images and write CSVs\n",
    "for split_name, image_list in split_map.items():\n",
    "    out_dir = split_dirs[split_name]\n",
    "    anno_path = os.path.join(base_dir, f'anno_{split_name}.csv')\n",
    "\n",
    "    with open(anno_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        for img_name in image_list:\n",
    "            src_img = os.path.join(all_data_dir, img_name)\n",
    "            dst_img = os.path.join(out_dir, img_name)\n",
    "\n",
    "            # Move image\n",
    "            shutil.move(src_img, dst_img)\n",
    "\n",
    "            # Write corresponding annotation\n",
    "            writer.writerow(annotations[img_name])\n",
    "\n",
    "print(\"✅ Dataset split into train, validation, and test with corresponding annotations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
